{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000001",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Create Delta Tables from Hive DDL\n",
    "\n",
    "This notebook converts Hive/Impala DDL statements to Databricks Delta tables.\n",
    "\n",
    "**Features:**\n",
    "- Automatic type optimization (STRING `_ts` columns → TIMESTAMP)\n",
    "- Managed Delta tables with auto-optimization\n",
    "- Single file or batch processing\n",
    "- Dry-run mode to preview DDL\n",
    "\n",
    "**Prerequisites:**\n",
    "- Hive DDL files uploaded to Volumes\n",
    "- Appropriate permissions on target catalog/schema\n",
    "- Active cluster (serverless or all-purpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000002",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Import the table creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000003",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Add the schema migration tool to Python path\n",
    "sys.path.append(\"/Workspace/Users/eliao@bpcs.com/nifi_to_databricks_test/tools/schema_migration_tool\")\n",
    "\n",
    "from create_delta_tables import create_tables_from_hive_ddl\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000004",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Set your target catalog and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000005",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Target Databricks catalog and schema\n",
    "TARGET_CATALOG = \"eliao\"\n",
    "TARGET_SCHEMA = \"nifi_to_databricks\"\n",
    "\n",
    "print(f\"Target location: {TARGET_CATALOG}.{TARGET_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000006",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Option 1: Single File Processing\n",
    "\n",
    "Convert a single Hive DDL file to Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000007",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Single file - update the path to your DDL file\n",
    "SINGLE_FILE_PATH = \"/Volumes/eliao/nifi_to_databricks/test_data_files/test.sql\"\n",
    "\n",
    "result = create_tables_from_hive_ddl(\n",
    "    input_file=SINGLE_FILE_PATH,\n",
    "    catalog=TARGET_CATALOG,\n",
    "    schema=TARGET_SCHEMA,\n",
    "    optimize_types=True  # Convert _ts columns to TIMESTAMP\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RESULT\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"✓ Successfully created: {result['success_count']} table(s)\")\n",
    "print(f\"✗ Failed: {result['fail_count']} table(s)\")\n",
    "print(f\"Total processed: {result['total']} file(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000008",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Single File - Dry Run\n",
    "\n",
    "Preview the DDL without creating tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000009",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dry run - just show what would be created\n",
    "result = create_tables_from_hive_ddl(\n",
    "    input_file=SINGLE_FILE_PATH,\n",
    "    catalog=TARGET_CATALOG,\n",
    "    schema=TARGET_SCHEMA,\n",
    "    optimize_types=True,\n",
    "    dry_run=True  # Only preview, don't create\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000010",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Option 2: Batch Processing\n",
    "\n",
    "Process multiple DDL files from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000011",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Batch processing - update the path to your directory containing .sql files\n",
    "BATCH_DIRECTORY = \"/Volumes/eliao/nifi_to_databricks/hive_ddls/\"\n",
    "\n",
    "result = create_tables_from_hive_ddl(\n",
    "    input_dir=BATCH_DIRECTORY,\n",
    "    catalog=TARGET_CATALOG,\n",
    "    schema=TARGET_SCHEMA,\n",
    "    optimize_types=True  # Convert _ts columns to TIMESTAMP\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"BATCH PROCESSING RESULT\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"✓ Successfully created: {result['success_count']} table(s)\")\n",
    "print(f\"✗ Failed: {result['fail_count']} table(s)\")\n",
    "print(f\"Total processed: {result['total']} file(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000012",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Batch Processing - Dry Run\n",
    "\n",
    "Preview all tables without creating them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000013",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dry run for batch - see DDL for all files\n",
    "result = create_tables_from_hive_ddl(\n",
    "    input_dir=BATCH_DIRECTORY,\n",
    "    catalog=TARGET_CATALOG,\n",
    "    schema=TARGET_SCHEMA,\n",
    "    optimize_types=True,\n",
    "    dry_run=True  # Only preview, don't create\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000014",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Verify Created Tables\n",
    "\n",
    "Check that tables were created successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000015",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Show all tables in the target schema\n",
    "SHOW TABLES IN eliao.nifi_to_databricks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000016",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Describe a specific table (update table name)\n",
    "DESCRIBE EXTENDED eliao.nifi_to_databricks.obf_table_raw;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000017",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Advanced Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000018",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Without Type Optimization\n",
    "\n",
    "Keep _ts columns as STRING instead of converting to TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000019",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Process without type optimization\n",
    "result = create_tables_from_hive_ddl(\n",
    "    input_file=SINGLE_FILE_PATH,\n",
    "    catalog=TARGET_CATALOG,\n",
    "    schema=TARGET_SCHEMA,\n",
    "    optimize_types=False  # Keep original STRING types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000020",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Custom Catalog and Schema\n",
    "\n",
    "Create tables in different catalog/schema combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000021",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create in dev environment\n",
    "result_dev = create_tables_from_hive_ddl(\n",
    "    input_file=SINGLE_FILE_PATH,\n",
    "    catalog=\"dev\",\n",
    "    schema=\"bronze\"\n",
    ")\n",
    "\n",
    "# Create in prod environment\n",
    "result_prod = create_tables_from_hive_ddl(\n",
    "    input_file=SINGLE_FILE_PATH,\n",
    "    catalog=\"prod\",\n",
    "    schema=\"bronze\"\n",
    ")\n",
    "\n",
    "print(f\"Dev: {result_dev['success_count']} tables created\")\n",
    "print(f\"Prod: {result_prod['success_count']} tables created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000022",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000023",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Check if schema exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000024",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW SCHEMAS IN eliao LIKE 'nifi*';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000025",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Check catalog permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000026",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SHOW GRANTS ON CATALOG eliao;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000027",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### View table properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000028",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- View Delta table properties\n",
    "SHOW TBLPROPERTIES eliao.nifi_to_databricks.obf_table_raw;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00000000-0000-0000-0000-000000000029",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Notes\n",
    "\n",
    "- Tables are created as **managed Delta tables** (no LOCATION clause)\n",
    "- Partitioning is preserved from the Hive table\n",
    "- Auto-optimization is enabled by default\n",
    "- Tables are created **empty** (structure only, no data)\n",
    "- To load data, use separate `INSERT INTO` or data migration tools"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Create_Delta_Tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
